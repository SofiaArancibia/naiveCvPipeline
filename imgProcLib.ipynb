{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decisions**:\n",
    "    - I did the unzipping manually\n",
    "\n",
    "### **Assumptions**:\n",
    "    - I don't have duplicated images\n",
    "\n",
    "### **Improvements**:\n",
    "    - Process images (resizing and cropping) in grayscale to reduce space and compute complexity\n",
    "    - Create an external samples folder to store image samples. A good practice is to save raw, interim and processed data for experiments reproducibility purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(file)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_size(img, size):\n",
    "    '''\n",
    "    description:\n",
    "        Returns True or False depending on the image having a specific size passed as argument\n",
    "    input:\n",
    "        - img: cv2 image\n",
    "        - size: list [height, width, depth]\n",
    "    output:\n",
    "        - check: boolean\n",
    "    '''\n",
    "    #TODO: check if 'size' has 3 elements\n",
    "    (height, width, depth) = img.shape    \n",
    "    return (height, width, depth) == tuple(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size):\n",
    "    #TODO: check if 'size' has 3 elements\n",
    "    \n",
    "    if (isinstance(size, list)):\n",
    "        size = tuple(size)\n",
    "    \n",
    "    print(size)\n",
    "    \n",
    "    resized = cv2.resize(img, size)\n",
    "    print(\"Original Size: {}\".format(img.shape))\n",
    "    print(\"Resized Size: {}\".format(resized.shape))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, roi_size, shift, center=True):\n",
    "    #TODO: check if 'roi_size' has 3 elements\n",
    "    #TODO: allow to center=False\n",
    "    #TODO: allow specify a corner as 'shift' value\n",
    "    #TODO: check if roi_size is under the image boundaries\n",
    "    \n",
    "    '''\n",
    "    description: Crops an image to size 'roi_size'. \n",
    "    The center of the image is the default shift, but if center = False, a shift value must be provided in the form [center+y, center+x]\n",
    "    input:\n",
    "        - img: cv2 image\n",
    "        - roi_size: list [roi_height, roi_width]\n",
    "        - shift: list [y_shift, x_shift]\n",
    "        - center: boolean \n",
    "    output:\n",
    "        - crop_img: cv image\n",
    "    '''\n",
    "    height, width, _ = img.shape  \n",
    "    img_center = [height/2, width/2]\n",
    "    if center:\n",
    "        crop_img = img[img_center[0]-roi_size[0]/2:img_center[0]+roi_size[0]/2, img_center[1]-roi_size[1]/2:img_center[1]+roi_size[1]/2]\n",
    "    else:\n",
    "        if shift:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('shift value must be setted when center=False')\n",
    "    \n",
    "    print(\"Original Size: {}\".format(img.shape))\n",
    "    print(\"Cropped Size: {}\".format(crop_img.shape))\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def get_random_corner(y_limit, x_limit):\n",
    "    return [randint(0, y_limit), randint(0, x_limit)]\n",
    "\n",
    "def check_corners(corner, corner_lists, sample_size):\n",
    "    for c in corner_lists:\n",
    "        ly = c[0] + sample_size[0]\n",
    "        lx = c[1] + sample_size[1]\n",
    "        overlap = False\n",
    "        if ((corner[0] >= c[0] and corner[0] < ly) or ( corner[0] > c[0] and corner[0] <= ly)) and ((corner[1] >= c[1] and corner[1] < lx) or ( corner[1] > c[1] and corner[1] <= lx)):           \n",
    "            overlap = True    \n",
    "            return overlap\n",
    "    return overlap         \n",
    "        \n",
    "\n",
    "def extract_samples(img, sample_size, overlap=False, num_samples=3):\n",
    "    '''\n",
    "    description: Extract 'num_samples' samples of 'sample_size' size from 'img'. \n",
    "    input:\n",
    "        - img: cv2 image\n",
    "        - num_samples: int\n",
    "        - sample_size: list [sample_height, sample_width]\n",
    "        - overlap: boolean \n",
    "    output:\n",
    "        - samples: cv images list\n",
    "    '''\n",
    "    corners = list()\n",
    "    samples = list()\n",
    "    for i in range(0,num_samples):\n",
    "        corner = get_random_corner(sample_size[0], sample_size[1])\n",
    "        corners.append(corner)\n",
    "        if not overlap:\n",
    "            corner = get_random_corner(sample_size[0], sample_size[1])\n",
    "            check = check_corners(corner, corners, sample_size)\n",
    "            while(check):\n",
    "                corner = get_random_corner(sample_size[0], sample_size[1])\n",
    "            corners.append(corner)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for c in corners:\n",
    "        sample = img[c[0]:c[0]+sample_size[0],c[1]:c[1]+sample_size[1]]\n",
    "        samples.append(sample)      \n",
    "    \n",
    "    return samples    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test = 0.3, shuffle = True):\n",
    "    '''\n",
    "    description: Splits a dataset of samples into training and testing sets. \n",
    "    input:\n",
    "        - data: dict\n",
    "        - test: float\n",
    "        - shuffle: boolean\n",
    "    output:\n",
    "        - train: list\n",
    "        - test: list\n",
    "    '''\n",
    "    \n",
    "    points = len(data)\n",
    "    test_len = int(test*points)\n",
    "    keys =  list(data.keys())\n",
    "    train = list()\n",
    "    test = list()\n",
    "    counter = 0\n",
    "    \n",
    "    if shuffle:\n",
    "        shuffle(keys)\n",
    "    \n",
    "    for key in keys:\n",
    "        if counter<=test_len:\n",
    "            test.extend(data[key])\n",
    "        train.extend(data[key])\n",
    "    \n",
    "    return train, test    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ML Engineer task/ML Engineer task/sample_frames/sample_frames/10wh903u4rtuc1k643aqepn4yi_main_3573.jpeg\n",
      "(480, 270, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b7d0b37fbea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Resize if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Crop the image down to the central 270x270x3 region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-409bdf129586>\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(img, size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resized Size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "images_path = \"ML Engineer task/ML Engineer task/sample_frames/sample_frames/*\"\n",
    "files = glob.glob(images_path)\n",
    "\n",
    "img_size = [480, 270, 3]\n",
    "roi_size = [270, 270, 3]\n",
    "sample_size = [80, 80, 3]\n",
    "\n",
    "samples = dict()\n",
    "counter = 0\n",
    "for file in files:\n",
    "    print(\"Processing file: {}\".format(file))\n",
    "    img = cv2.imread(file) #TODO: check if 'file' is an image\n",
    "    cv2.imshow(\"Read image\", img)\n",
    "    check = check_image_size(img, img_size) # Ensure each image is 480 x 270 x 3\n",
    "    \n",
    "    if not check: # Resize if required\n",
    "        img = resize_image(img, img_size) \n",
    "    \n",
    "    # Crop the image down to the central 270x270x3 region\n",
    "    img = crop_image(img, roi_size, _, center=True)\n",
    "    \n",
    "    # Randomly extract 3, 80 x 80 x 3 samples that do not overlap\n",
    "    samples['img{}_samples'.format(counter)] = extract_samples(img, sample_size, overlap=False, num_samples=3)\n",
    "    counter += 1\n",
    "    \n",
    "# Allow for shuffling & separation into training & test sets. \n",
    "# The proportions of which should be able to be defined by the end user. \n",
    "# Samples from the same image should not appear in both training and test sets.\n",
    "\n",
    "train, test  = train_test_split(samples, test = 0.3, shuffle = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
